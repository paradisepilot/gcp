

*** Reading remote log from gs://us-central1-gauss100-2021-1-46ca948c-bucket/logs/gauss100_gke/create_node_pool/2021-11-28T18:34:31.889508+00:00/1.log.
[2021-11-28 18:34:44,703] {taskinstance.py:671} INFO - Dependencies all met for <TaskInstance: gauss100_gke.create_node_pool 2021-11-28T18:34:31.889508+00:00 [queued]>
[2021-11-28 18:34:44,793] {taskinstance.py:671} INFO - Dependencies all met for <TaskInstance: gauss100_gke.create_node_pool 2021-11-28T18:34:31.889508+00:00 [queued]>
[2021-11-28 18:34:44,793] {taskinstance.py:881} INFO - 
--------------------------------------------------------------------------------
[2021-11-28 18:34:44,794] {taskinstance.py:882} INFO - Starting attempt 1 of 1
[2021-11-28 18:34:44,794] {taskinstance.py:883} INFO - 
--------------------------------------------------------------------------------
[2021-11-28 18:34:44,818] {taskinstance.py:902} INFO - Executing <Task(BashOperator): create_node_pool> on 2021-11-28T18:34:31.889508+00:00
[2021-11-28 18:34:44,822] {standard_task_runner.py:54} INFO - Started process 2403 to run task
[2021-11-28 18:34:44,874] {standard_task_runner.py:77} INFO - Running: ['airflow', 'run', 'gauss100_gke', 'create_node_pool', '2021-11-28T18:34:31.889508+00:00', '--job_id', '42', '--pool', 'default_pool', '--raw', '-sd', 'DAGS_FOLDER/dag-gauss100.py', '--cfg_path', '/tmp/tmpmrj8o51u']
[2021-11-28 18:34:44,876] {standard_task_runner.py:78} INFO - Job 42: Subtask create_node_pool
[2021-11-28 18:34:45,546] {logging_mixin.py:120} INFO - Running <TaskInstance: gauss100_gke.create_node_pool 2021-11-28T18:34:31.889508+00:00 [running]> on host airflow-worker-6cc67f6545-hqd7s
[2021-11-28 18:34:45,917] {bash_operator.py:114} INFO - Tmp dir root location: 
 /tmp
[2021-11-28 18:34:45,920] {bash_operator.py:137} INFO - Temporary script location: /tmp/airflowtmp7fy649gd/create_node_pooll1p85x2b
[2021-11-28 18:34:45,920] {bash_operator.py:147} INFO - Running command: 
    # Set some environment variables in case they were not set already
    [ -z "${NODE_COUNT}" ] && NODE_COUNT=3
    [ -z "${MACHINE_TYPE}" ] && MACHINE_TYPE=n1-standard-2
    [ -z "${SCOPES}" ] && SCOPES=default,cloud-platform
    [ -z "${NODE_DISK_SIZE}" ] && NODE_DISK_SIZE=20

    # Generate node-pool name
    NODE_POOL=ndpl-$(echo 20211128T183431 | awk '{print tolower($0)}')

    echo
    echo COMPOSER_GKE_ZONE=${COMPOSER_GKE_ZONE}

    echo
    echo COMPOSER_GKE_NAME=${COMPOSER_GKE_NAME}

    echo
    echo NODE_POOL=${NODE_POOL}

    echo
    echo MACHINE_TYPE=${MACHINE_TYPE}

    echo
    echo NODE_COUNT=${NODE_COUNT}

    echo
    echo NODE_DISK_SIZE=${NODE_DISK_SIZE}

    echo
    echo SCOPES=${SCOPES}

    # It is important to set container/cluster; otherwise, Composer would
    # throw an error at the node pool creation command below
    # due to the fact that the node pool creation would require more vCPU
    # than regional vCPU quota.
    echo
    echo Executing: gcloud config set container/cluster ${COMPOSER_GKE_NAME}
    echo
    gcloud config set container/cluster ${COMPOSER_GKE_NAME}

    echo
    echo Executing: gcloud container node-pools create ...
    echo
    gcloud container node-pools create ${NODE_POOL}         --project=${GCP_PROJECT}       --cluster=${COMPOSER_GKE_NAME} --zone=${COMPOSER_GKE_ZONE}         --machine-type=${MACHINE_TYPE} --num-nodes=${NODE_COUNT}      --disk-size=${NODE_DISK_SIZE}           --scopes=${SCOPES}         --enable-autoupgrade

    # Set the airflow variable name
    echo
    echo Executing: airflow variables -s node_pool ${NODE_POOL}
    echo
    airflow variables -s node_pool ${NODE_POOL}
    
[2021-11-28 18:34:46,077] {bash_operator.py:154} INFO - Output:
[2021-11-28 18:34:46,084] {bash_operator.py:158} INFO - 
[2021-11-28 18:34:46,085] {bash_operator.py:158} INFO - COMPOSER_GKE_ZONE=us-central1-a
[2021-11-28 18:34:46,086] {bash_operator.py:158} INFO - 
[2021-11-28 18:34:46,086] {bash_operator.py:158} INFO - COMPOSER_GKE_NAME=us-central1-gauss100-2021-1-46ca948c-gke
[2021-11-28 18:34:46,086] {bash_operator.py:158} INFO - 
[2021-11-28 18:34:46,086] {bash_operator.py:158} INFO - NODE_POOL=ndpl-20211128t183431
[2021-11-28 18:34:46,086] {bash_operator.py:158} INFO - 
[2021-11-28 18:34:46,087] {bash_operator.py:158} INFO - MACHINE_TYPE=n1-standard-2
[2021-11-28 18:34:46,087] {bash_operator.py:158} INFO - 
[2021-11-28 18:34:46,087] {bash_operator.py:158} INFO - NODE_COUNT=3
[2021-11-28 18:34:46,087] {bash_operator.py:158} INFO - 
[2021-11-28 18:34:46,088] {bash_operator.py:158} INFO - NODE_DISK_SIZE=20
[2021-11-28 18:34:46,088] {bash_operator.py:158} INFO - 
[2021-11-28 18:34:46,088] {bash_operator.py:158} INFO - SCOPES=default,cloud-platform
[2021-11-28 18:34:46,088] {bash_operator.py:158} INFO - 
[2021-11-28 18:34:46,089] {bash_operator.py:158} INFO - Executing: gcloud config set container/cluster us-central1-gauss100-2021-1-46ca948c-gke
[2021-11-28 18:34:46,089] {bash_operator.py:158} INFO - 
[2021-11-28 18:34:47,175] {bash_operator.py:158} INFO - Updated property [container/cluster].
[2021-11-28 18:34:47,287] {bash_operator.py:158} INFO - 
[2021-11-28 18:34:47,287] {bash_operator.py:158} INFO - Executing: gcloud container node-pools create ...
[2021-11-28 18:34:47,323] {bash_operator.py:158} INFO - 
[2021-11-28 18:34:53,174] {bash_operator.py:158} INFO - WARNING: Starting with version 1.19, newly created node-pools will have COS_CONTAINERD as the default node image when no image type is specified.
[2021-11-28 18:34:53,939] {bash_operator.py:158} INFO - Creating node pool ndpl-20211128t183431...
[2021-11-28 18:36:24,645] {bash_operator.py:158} INFO - ....................................................................................................................................................................................................................................................................................................................................................................................................................................................................done.
[2021-11-28 18:36:24,721] {bash_operator.py:158} INFO - Created [https://container.googleapis.com/v1/projects/gauss100-2021-11-13-a/zones/us-central1-a/clusters/us-central1-gauss100-2021-1-46ca948c-gke/nodePools/ndpl-20211128t183431].
[2021-11-28 18:36:24,727] {bash_operator.py:158} INFO - NAME                  MACHINE_TYPE   DISK_SIZE_GB  NODE_VERSION
[2021-11-28 18:36:24,729] {bash_operator.py:158} INFO - ndpl-20211128t183431  n1-standard-2  20            1.20.10-gke.1600
[2021-11-28 18:36:24,918] {bash_operator.py:158} INFO - 
[2021-11-28 18:36:24,919] {bash_operator.py:158} INFO - Executing: airflow variables -s node_pool ndpl-20211128t183431
[2021-11-28 18:36:24,919] {bash_operator.py:158} INFO - 
[2021-11-28 18:36:27,891] {bash_operator.py:158} INFO - [2021-11-28 18:36:27,890] {configuration.py:732} INFO - Reading the config from /etc/airflow/airflow.cfg
[2021-11-28 18:36:28,042] {bash_operator.py:158} INFO - [2021-11-28 18:36:28,041] {configuration.py:732} INFO - Reading the config from /etc/airflow/airflow.cfg
[2021-11-28 18:36:28,183] {bash_operator.py:158} INFO - The 'variables' command is deprecated and removed in Airflow 2.0, please use 'variables list' instead
[2021-11-28 18:36:33,878] {bash_operator.py:162} INFO - Command exited with return code 0
[2021-11-28 18:36:34,484] {taskinstance.py:1071} INFO - Marking task as SUCCESS.dag_id=gauss100_gke, task_id=create_node_pool, execution_date=20211128T183431, start_date=20211128T183444, end_date=20211128T183634
[2021-11-28 18:36:37,734] {local_task_job.py:102} INFO - Task exited with return code 0


